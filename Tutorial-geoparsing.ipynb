{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YrOKr9pwkxJw"
   },
   "source": [
    "# GEOPARSING THE ENCYCLOPEDIE\n",
    "\n",
    "This notebook is proposed by [L. Moncla](https://ludovicmoncla.github.io/) and [K. McDonough](https://www.turing.ac.uk/people/researchers/katherine-mcdonough) as part of the [GEODE](https://geode-project.github.io) (2020-2024) project.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](http://colab.research.google.com/github/GEODE-project/perdido-geoparsing-notebook/master/Tutorial-geoparsing.ipynb)\n",
    "[![Binder](https://mybinder.org/badge_logo.svg)](https://mybinder.org/v2/gh/GEODE-project/perdido-geoparsing-notebook/master?filepath=Tutorial-geoparsing.ipynb)\n",
    "\n",
    "\n",
    "## 1. Overview\n",
    "\n",
    "\n",
    "In this tutorial, we'll learn about a few different things:\n",
    "\n",
    "\n",
    "- Load a dataset from the `Perdido` library as a Python dataframe (articles from Diderot and d'Alembert's *Encyclopédie*)\n",
    "  - Use Python dataframe for simple data analysis\n",
    "- Use the `Perdido Geoparser` library for geoparsing French texts\n",
    "  - Display geotagging results\n",
    "  - Map geocoding results\n",
    "- Compare `Perdido` NER results with `spaCy` and `Stanza` (python libraries)\n",
    "- Reflect on the limits of geoparsing historical French (and multilingual) texts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5gi1PFqtkxJy"
   },
   "source": [
    "## 2. Introduction\n",
    "\n",
    "Geoparsing (also known as toponym resolution) refers to the process of extracting place names from text and assigning geographic coordinates to them.\n",
    "This involves two main tasks: geotagging and geocoding.\n",
    "Geotagging consists to identify spans of text referring to place names while geocoding consists to find unambiguous geographic coordinates.\n",
    "\n",
    "Geographic text analysis research in the digital humanities has focused on projects analyzing modern English-language corpora. \n",
    "In this tutorial we propose to highlight the difficulties of extracting and mapping geographical information from historical French texts.\n",
    "As we'll see in the following, in addition to the problem of language when it comes to historical documents, the early-modern period lacks temporally appropriate gazetteers.\n",
    "\n",
    "> McDonough, K., Moncla, L., & van de Camp, M. (2019). Named entity recognition goes to old regime France: geographic text analysis for early modern French corpora. International Journal of Geographical Information Science, 33, 2498–2522.\n",
    "\n",
    "\n",
    "### Discussion Part 1\n",
    "\n",
    "1. Input/output: what do you need for geoparsing, and what do you get at the end?\n",
    "2. How is geoparsing related to other NLP tasks?\n",
    "3. Why is geoparsing an unsolved task in GIScience?\n",
    "4. What methods allow us to evaluate the results of automatic geoparsing?\n",
    "5. What kinds of humanities research questions can we answer using the results of geoparsing?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 The Perdido Geoparser python library\n",
    "\n",
    "[Perdido](https://github.com/ludovicmoncla/perdido) is a python text geoparser. It provides NLP and GIS methods for geoparsing French texts.\n",
    "It has initially been developed as a REST API for extracting and retrieving displacements from French hiking descriptions, under the framework of the [PERDIDO](http://erig.univ-pau.fr/PERDIDO/) and [ANR Choucas](http://choucas.ign.fr) projects.\n",
    "\n",
    "More recently, as part of the [GEODE project](https://geode-project.github.io) we have developed a custom version for historical documents and more specifically for the Encyclopédie.\n",
    "\n",
    "\n",
    "In this tutorial we'll see how to use the `Perdido` python library for geoparsing French texts. \n",
    "We will apply geoparsing on volume 7 of Encyclopedie corpus version released by the [ARTFL project](https://encyclopedie.uchicago.edu/) and we'll show the limits of geotagging and geocoding historical documents.\n",
    "\n",
    "### 2.2 Acknowledgement\n",
    "\n",
    "Data courtesy the [ARTFL Encyclopédie Project](https://artfl-project.uchicago.edu/), University of Chicago.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Setting up the environment\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Install python packages\n",
    "\n",
    "* If you already configured your environment using conda (`environment.yml`) or pip (`requirements.txt`), you can skip this step and go to section [3.2 Import the libraries](3.2-Import-the-libraries).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install perdido==0.1.27\n",
    "!pip install stanza==1.4.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Import the libraries\n",
    "\n",
    "First, we will load some specific libraries from `Perdido` that we will use in this notebook. Next, we import some tools that will help us parse and visualize the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from perdido.geoparser import Geoparser\n",
    "from perdido.geocoder import Geocoder\n",
    "from perdido.datasets import load_edda_artfl, load_edda_perdido\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b9ZN6YgcnxdK"
   },
   "source": [
    "\n",
    "## 4. Getting started\n",
    "\n",
    "In this notebook, we'll test out some basic queries of the *Encyclopédie* articles from volume 7 (H - Itzehoa, published in 1765). You can learn more about the other volumes [here](https://encyclopedie.uchicago.edu/node/102).\n",
    "\n",
    "\n",
    "### 4.1 Loading the ARTFL *Encyclopédie* dataset\n",
    "\n",
    "First, we load the data. You can view this sample dataset at under the 'Data' directory [here](https://github.com/GEODE-project/perdido-geoparsing-notebook).\n",
    "\n",
    "The next cell loads the data from the Perdido library, defines the data as `dataset`, and shows you the top 5 records (using the [head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) method from the [Pandas](https://pandas.pydata.org/docs/index.html) library). The data has been saved as a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>head</th>\n",
       "      <th>normClass</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>volume07-1.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Title Page</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>unsigned</td>\n",
       "      <td>ENCYCLOPÉDIE, ou DICTIONNAIRE RAISONNÉ DES SCI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>volume07-10.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>FOESNE ou FOUANE</td>\n",
       "      <td>Marine | Pêche</td>\n",
       "      <td>Bellin</td>\n",
       "      <td>FOESNE ou FOUANE, sub. s. (Marine &amp; Pêche.) c'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>volume07-100.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>100</td>\n",
       "      <td>Fond de la hune</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Bellin</td>\n",
       "      <td>Fond de la hune ; ce sont les planches qu on p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>volume07-1000.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1000</td>\n",
       "      <td>Fronteau</td>\n",
       "      <td>Bourrelier | Sellier</td>\n",
       "      <td>Diderot</td>\n",
       "      <td>* Fronteau, terme de Sellier-Bourrelier ; c'es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>volume07-1001.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1001</td>\n",
       "      <td>FRONTIERE</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Diderot</td>\n",
       "      <td>* FRONTIERE, s. f. (Géog.) se dit des limites,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  volume  number              head             normClass  \\\n",
       "0     volume07-1.tei       7       1        Title Page          unclassified   \n",
       "1    volume07-10.tei       7      10  FOESNE ou FOUANE        Marine | Pêche   \n",
       "2   volume07-100.tei       7     100   Fond de la hune          unclassified   \n",
       "3  volume07-1000.tei       7    1000          Fronteau  Bourrelier | Sellier   \n",
       "4  volume07-1001.tei       7    1001         FRONTIERE            Géographie   \n",
       "\n",
       "     author                                               text  \n",
       "0  unsigned  ENCYCLOPÉDIE, ou DICTIONNAIRE RAISONNÉ DES SCI...  \n",
       "1    Bellin  FOESNE ou FOUANE, sub. s. (Marine & Pêche.) c'...  \n",
       "2    Bellin  Fond de la hune ; ce sont les planches qu on p...  \n",
       "3   Diderot  * Fronteau, terme de Sellier-Bourrelier ; c'es...  \n",
       "4   Diderot  * FRONTIERE, s. f. (Géog.) se dit des limites,...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = load_edda_artfl()\n",
    "dataset = d['data']\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Exploring the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have access to all the attributes and methods of the [dataframe](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html) object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3385 entries, 0 to 3384\n",
      "Data columns (total 7 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   filename   3385 non-null   object\n",
      " 1   volume     3385 non-null   int64 \n",
      " 2   number     3385 non-null   int64 \n",
      " 3   head       3384 non-null   object\n",
      " 4   normClass  3384 non-null   object\n",
      " 5   author     3384 non-null   object\n",
      " 6   text       3385 non-null   object\n",
      "dtypes: int64(2), object(5)\n",
      "memory usage: 185.2+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can notice that all the columns do not have the same number of records (3384 vs. 3385). \n",
    "One record do not have values for head, normClass and author.\n",
    "\n",
    "* Show this record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>head</th>\n",
       "      <th>normClass</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2719</th>\n",
       "      <td>volume07-4.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ENCYCLOPÉDIE, ou DICTIONNAIRE RAISONNÉ DES SCI...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            filename  volume  number head normClass author  \\\n",
       "2719  volume07-4.tei       7       4  NaN       NaN    NaN   \n",
       "\n",
       "                                                   text  \n",
       "2719  ENCYCLOPÉDIE, ou DICTIONNAIRE RAISONNÉ DES SCI...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset['head'].isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that this record does not refer to an article but only to a title. \n",
    "Having rows with missing values can cause issues depending on the process you do with the data. It is then better to remove this row from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dropna(inplace=True)     # dataset = dataset.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, print the number of rows in our dataframe which correspond to the number of articles in our corpus:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3384 articles in the dataset.\n"
     ]
    }
   ],
   "source": [
    "n = dataset.shape[0]\n",
    "print('There are ' + str(n) + ' articles in the dataset.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.1 Searching by metadata\n",
    "\n",
    "We can select articles based on their classification in the *Encyclopédie*. (There are actually a few different ways that the ARTFL *Encyclopédie* articles have been classified. In this notebook we will be using the `normclass` field, which normalizes classifications given at time of publication that had many spelling variants. \n",
    ")\n",
    "\n",
    "If we want all articles classified as 'Geography' we can make the request as follows (the output is stored as a new data frame `df_geo`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 496 geography articles (Géographie)\n"
     ]
    }
   ],
   "source": [
    "req = 'Géographie'\n",
    "df_geo = dataset[dataset['normClass'].str.contains(req, case=False)]\n",
    "\n",
    "n = df_geo.shape[0]\n",
    "print('There are ' + str(n) + ' geography articles ('+ req +')')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can query based on any value in the dataframe (e.g. article metadata). For instance, we can query all the articles written by a specific author:\n",
    "\n",
    "* Count article for a single named author (Jaucourt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "476 were written by Jaucourt\n"
     ]
    }
   ],
   "source": [
    "val = 'Jaucourt'\n",
    "n = df_geo.loc[dataset['author'] == val].shape[0]\n",
    "print(str(n) + ' were written by '+ val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also easily show the number of articles per author:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "Desmarest                            1\n",
       "Diderot                              1\n",
       "Jaucourt                           476\n",
       "La Condamine                         1\n",
       "Mallet                               1\n",
       "Robert de Vaugondy                   2\n",
       "Robert de Vaugondy & d'Alembert      1\n",
       "unsigned                            13\n",
       "Name: filename, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_geo.groupby(['author'])[\"filename\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to show the value of one column in our dataframe for a specific row (i.e., by article) based on its name. For instance, if we want to know who wrote the article about Frontignan or if we want to see its content, we make these requests:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Jaucourt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset['head'] == 'FRONTIGNAN'].author.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2.2 Searching by text \n",
    "\n",
    "It is also possible to display and search the full text content of the articles stored in the dataframe. \n",
    "\n",
    "* Show full text for a specific article:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FRONTIGNAN, (Géog.) petite ville de France. au Bas-Languedoc, connue par ses excellens vins muscats, & ses raisins de caisse qu'on appelle passerilles. Quelques savans croyent, sans en donner de preuves, que cette ville est le forum Domitii des Romains. Elle est située sur l'étang de Maguelone, à six lieues N. E. d'Agde, & cinq S. O. de Montpellier. Long. 15d. 24'. lat. 43d. 28'. (D. J.)\""
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.loc[dataset['head'] == 'FRONTIGNAN'].text.item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also perform a **keyword search** over the text content of all articles:\n",
    "\n",
    "* Select articles that contain 'france':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239 articles contain the word 'france'\n"
     ]
    }
   ],
   "source": [
    "# search corpus by keyword (val)\n",
    "val = 'france'\n",
    "df_2 = dataset[dataset['text'].str.contains(val, case=False)]\n",
    "print(str(df_2.shape[0]) + ' articles contain the word \\''+ val + '\\'')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also possible to search by **phrases**. The expression \"ville de\" is commonly used in the *Encyclopédie* to define the country or region of a place. Searching by this phrase gives us a sense of the broader geographical coverage of the corpus. \n",
    "\n",
    "Here we extract all articles that contain the expression 'ville de':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>head</th>\n",
       "      <th>normClass</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>volume07-1002.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1002</td>\n",
       "      <td>FRONTIGNAN</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>FRONTIGNAN, (Géog.) petite ville de France. au...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>volume07-1072.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1072</td>\n",
       "      <td>FUM-CHIM</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>FUM-CHIM, (Géog.) petite ville de la province ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>volume07-1092.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1092</td>\n",
       "      <td>FUNCHAL</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>FUNCHAL, (Géog.) ville de l'Océan atlantique, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>volume07-1100.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1100</td>\n",
       "      <td>Funérailles des Romains</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>Funérailles des Romains. Les Romains ont eté s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>volume07-1114.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1114</td>\n",
       "      <td>FUNG</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>FUNG, (Géog.) ville de la Chine, dans la provi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>volume07-901.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>901</td>\n",
       "      <td>FRIAS</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>FRIAS, (Géog.) petite ville de la Castille vie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3279</th>\n",
       "      <td>volume07-903.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>903</td>\n",
       "      <td>Fribourg</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>Fribourg, Friburgum, (Géog.) ville de Suisse f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3282</th>\n",
       "      <td>volume07-906.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>906</td>\n",
       "      <td>FRICENTI</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>FRICENTI, en latin moderne Fricentium, (Géog.)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3288</th>\n",
       "      <td>volume07-911.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>911</td>\n",
       "      <td>FRIDERICKSTADT</td>\n",
       "      <td>Géographie</td>\n",
       "      <td>Jaucourt</td>\n",
       "      <td>FRIDERICKSTADT, (Géog.) petite ville de la pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3362</th>\n",
       "      <td>volume07-979.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>979</td>\n",
       "      <td>FRONDE</td>\n",
       "      <td>Histoire | Méchanique</td>\n",
       "      <td>Le Blond &amp; d'Alembert</td>\n",
       "      <td>FRONDE, s. f. (Hist. &amp; Méchan.) instrument de ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>177 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  volume  number                     head  \\\n",
       "5     volume07-1002.tei       7    1002               FRONTIGNAN   \n",
       "82    volume07-1072.tei       7    1072                 FUM-CHIM   \n",
       "104   volume07-1092.tei       7    1092                  FUNCHAL   \n",
       "114   volume07-1100.tei       7    1100  Funérailles des Romains   \n",
       "129   volume07-1114.tei       7    1114                     FUNG   \n",
       "...                 ...     ...     ...                      ...   \n",
       "3277   volume07-901.tei       7     901                    FRIAS   \n",
       "3279   volume07-903.tei       7     903                 Fribourg   \n",
       "3282   volume07-906.tei       7     906                 FRICENTI   \n",
       "3288   volume07-911.tei       7     911           FRIDERICKSTADT   \n",
       "3362   volume07-979.tei       7     979                   FRONDE   \n",
       "\n",
       "                  normClass                 author  \\\n",
       "5                Géographie               Jaucourt   \n",
       "82               Géographie               Jaucourt   \n",
       "104              Géographie               Jaucourt   \n",
       "114            unclassified               Jaucourt   \n",
       "129              Géographie               Jaucourt   \n",
       "...                     ...                    ...   \n",
       "3277             Géographie               Jaucourt   \n",
       "3279             Géographie               Jaucourt   \n",
       "3282             Géographie               Jaucourt   \n",
       "3288             Géographie               Jaucourt   \n",
       "3362  Histoire | Méchanique  Le Blond & d'Alembert   \n",
       "\n",
       "                                                   text  \n",
       "5     FRONTIGNAN, (Géog.) petite ville de France. au...  \n",
       "82    FUM-CHIM, (Géog.) petite ville de la province ...  \n",
       "104   FUNCHAL, (Géog.) ville de l'Océan atlantique, ...  \n",
       "114   Funérailles des Romains. Les Romains ont eté s...  \n",
       "129   FUNG, (Géog.) ville de la Chine, dans la provi...  \n",
       "...                                                 ...  \n",
       "3277  FRIAS, (Géog.) petite ville de la Castille vie...  \n",
       "3279  Fribourg, Friburgum, (Géog.) ville de Suisse f...  \n",
       "3282  FRICENTI, en latin moderne Fricentium, (Géog.)...  \n",
       "3288  FRIDERICKSTADT, (Géog.) petite ville de la pre...  \n",
       "3362  FRONDE, s. f. (Hist. & Méchan.) instrument de ...  \n",
       "\n",
       "[177 rows x 7 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['text'].str.contains(\"ville de\", case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we can try a thematic search, for instance about 'esclavage' (slavery): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>volume</th>\n",
       "      <th>number</th>\n",
       "      <th>head</th>\n",
       "      <th>normClass</th>\n",
       "      <th>author</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>volume07-1409.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>1409</td>\n",
       "      <td>GALÉRIEN</td>\n",
       "      <td>Jurisprudence | Marine</td>\n",
       "      <td>unsigned</td>\n",
       "      <td>GALÉRIEN, s. m. (Jurisprud. Marine.) criminel ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>volume07-3054.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>3054</td>\n",
       "      <td>GROTESQUES</td>\n",
       "      <td>Beaux-Arts</td>\n",
       "      <td>Watelet</td>\n",
       "      <td>GROTESQUES, s. f. pl. (Beaux-Arts.) vient du m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2943</th>\n",
       "      <td>volume07-600.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>600</td>\n",
       "      <td>FOURRAGE</td>\n",
       "      <td>Maréchallerie</td>\n",
       "      <td>Bourgelat</td>\n",
       "      <td>FOURRAGE, s. m. (Maréchall.) nourriture des ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3054</th>\n",
       "      <td>volume07-700.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>700</td>\n",
       "      <td>Franc</td>\n",
       "      <td>unclassified</td>\n",
       "      <td>Boucher d'Argis</td>\n",
       "      <td>Franc signifie quelquefois une personne libre,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>volume07-770.tei</td>\n",
       "      <td>7</td>\n",
       "      <td>770</td>\n",
       "      <td>FRANÇOIS, ou FRANÇAIS</td>\n",
       "      <td>Littérature | Histoire | Morale</td>\n",
       "      <td>Voltaire</td>\n",
       "      <td>FRANÇOIS, ou FRANÇAIS, s. m. (Hist. Littérat. ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               filename  volume  number                   head  \\\n",
       "456   volume07-1409.tei       7    1409               GALÉRIEN   \n",
       "2283  volume07-3054.tei       7    3054             GROTESQUES   \n",
       "2943   volume07-600.tei       7     600               FOURRAGE   \n",
       "3054   volume07-700.tei       7     700                  Franc   \n",
       "3131   volume07-770.tei       7     770  FRANÇOIS, ou FRANÇAIS   \n",
       "\n",
       "                            normClass           author  \\\n",
       "456            Jurisprudence | Marine         unsigned   \n",
       "2283                       Beaux-Arts          Watelet   \n",
       "2943                    Maréchallerie        Bourgelat   \n",
       "3054                     unclassified  Boucher d'Argis   \n",
       "3131  Littérature | Histoire | Morale         Voltaire   \n",
       "\n",
       "                                                   text  \n",
       "456   GALÉRIEN, s. m. (Jurisprud. Marine.) criminel ...  \n",
       "2283  GROTESQUES, s. f. pl. (Beaux-Arts.) vient du m...  \n",
       "2943  FOURRAGE, s. m. (Maréchall.) nourriture des ch...  \n",
       "3054  Franc signifie quelquefois une personne libre,...  \n",
       "3131  FRANÇOIS, ou FRANÇAIS, s. m. (Hist. Littérat. ...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[dataset['text'].str.contains(\"esclavage\", case=False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "asi5amjhkxKA"
   },
   "source": [
    "## 5. The NLP pipeline: Perdido Geoparser\n",
    "\n",
    "\n",
    "In Natural Language Processing (NLP), the main first steps before processing text content consist in tokenizing sentences and words and assigning to each word its grammatical category (Part-of-Speech). \n",
    "\n",
    "This allows the construction of more complex rules or queries compared to a simple keyword search. E.g. we would know that \"city\" is a noun, and we can perform a search for all nouns in the corpus.\n",
    "\n",
    "\n",
    "These preprocessing steps are language dependent, and therefore we have to choose the right tool according to the language, style and period of our documents. This is a major difficulty when dealing with historical or ancient texts. For instance, for French it is difficult to find a POS tagger for pre-20th century French as major well known taggers are trained on contemporary corpora.\n",
    "\n",
    "> McDonough, K., Moncla, L., & van de Camp, M. (2019). Named entity recognition goes to old regime France: geographic text analysis for early modern French corpora. International Journal of Geographical Information Science, 33, 2498–2522.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nTcr95AokxKh"
   },
   "source": [
    "### 5.1 Perdido Geoparser\n",
    "\n",
    "\n",
    "The `Perdido` geoparser uses [Treetagger](https://www.cis.uni-muenchen.de/~schmid/tools/TreeTagger/) for part-of-speech tagging. \n",
    "\n",
    "\n",
    "The geotagging step of `Perdido` is perform using a cascade of finite-state transducers defining specific patterns for NER and identification of geographic information (spatial relations, etc.). \n",
    "> Mauro Gaio and Ludovic Moncla (2019). “Geoparsing and geocoding places in a dynamic space context.“ In The Semantics of Dynamic Space in French: Descriptive, experimental and formal studies on motion expression, 66, 353.\n",
    "\n",
    "Geoparsing in the digital humanities began with projects analyzing modern English-language corpora. But now, many researchers are developing projects for automatically identifying and geolocating places named in texts of many languages. \n",
    "\n",
    "Here we highlight the difficulties of extracting and mapping geographical information from historical French texts. In addition to language-related problems which impact the quality of tokenization, POS tagging, and NER, geocoding presents its own challenges. Once place names have been identifed in a text, correctly associating geographical coordinates with that place is a challenge. **Gazetteers** are knowledge bases that help researchers link place names with information about place, including its location. \n",
    "\n",
    "For our custom version of the `Perdido` Geoparser, the geocoding task uses a simple gazetteer lookup method. Several gazetteers can be used:\n",
    " - Nominatim (ie, OpenStreetMap) by default, \n",
    " - Geonames, \n",
    " - World Historical Gazetteer, \n",
    " - Pleiades\n",
    "\n",
    "Like using the most appropriate POS tagger, finding the best gazetteer for your corpus can be challenging. Luckily, for the ancient world, there are some excellent options. Here, you will also be able to test the [Pleiades gazetteer](https://pleiades.stoa.org/) and compare the results with the other contemporary gazetteers.\n",
    "\n",
    "\n",
    "The PERDIDO Geoparser returns XML-TEI. The `<name>` element refers to named entities (proper nouns) and the type attribute indicates its class (place, person, etc.). The `<rs>` element refers to extended named entities (e.g. ville d'Egypte). The `<location>` element indicates that geographic coordinates were found during geocoding.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Getting started with `Perdido`\n",
    "\n",
    "* Get the content from the article 'FRONTIGNAN' ([https://artflsrv03.uchicago.edu/philologic4/encyclopedie1117/navigate/7/1002/](https://artflsrv03.uchicago.edu/philologic4/encyclopedie1117/navigate/7/1002/)) from the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = dataset.loc[dataset['head'] == 'FRONTIGNAN'].text.item()\n",
    "content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Create a Geoparser object from the `Perdido` library. Specify that we are working with the *Encyclopédie* version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geoparser = Geoparser(version=\"Encyclopedie\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now you can use this geoparser for geoparsing text content. Let's try with the `content`variable that we declare before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = geoparser(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The geoparser return a `Perdido` object. This object has several attributes and methods. We'll now see some of them.\n",
    "\n",
    "* Accessing the XML-TEI result:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.tei"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Accessing the geojson results generate during the geocoding phase:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Transform the Perdido object into a dataframe (only some of the attributes are kept):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = doc.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Save the results in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_xml('FRONTIGNAN-perdido.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_geojson('FRONTIGNAN-perdido.geojson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.to_csv('FRONTIGNAN-perdido.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.3 Display named entities\n",
    "\n",
    "Often, it is useful to vizualize the output in sentence form. The `spacy` library provides a useful tool for this: `displacy`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc.to_spacy_doc(), style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc.to_spacy_doc(), style=\"span\", jupyter=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B7bw9rWGkxKx"
   },
   "source": [
    "#### 5.1.4 Map place names\n",
    "\n",
    "\n",
    "For many projects, it is important to view the results of geoparsing on a map. Here, we can see the results plotted on a map. But remember, these are only the results for which coordinates could be found. Results that could not be matched to records in the gazetteer will not be mapped.\n",
    "\n",
    "* Here we see the geocoding results for 'Frontignan' mapped:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Ay5XDTM1kxKy",
    "outputId": "93df6728-dd7e-40c7-c2c5-fae62699a7c0"
   },
   "outputs": [],
   "source": [
    "doc.get_folium_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.5 Try another example\n",
    "\n",
    "GESSORIACUM - https://artflsrv03.uchicago.edu/philologic4/encyclopedie1117/navigate/7/2046/\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content = dataset.loc[dataset['head'] == 'GESSORIACUM'].text.item()\n",
    "content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = geoparser(content)\n",
    "displacy.render(doc.to_spacy_doc(), style=\"ent\", jupyter=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.get_folium_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Comparison to other NER tools\n",
    "\n",
    "`Perdido` is a custom geoparsing library for French language documents. How does it compare to other state-of-the-art libraries?\n",
    "\n",
    "Comparing `Perdido`, `SpaCy`, and `Stanza` outputs, even for just 1-2 articles from our corpus, allows us to see common errors. One library might excel at identifying people, but struggle with complex place names. Another is better at capturing places named within phrases, but mixes up people and places. It is important to test multiple geoparsers for your corpus, and to understand how they can be adapted, in order to get the best results.\n",
    "\n",
    "### 6.1 SpaCy\n",
    "\n",
    "[SpaCy](https://spacy.io/) is a commonly-used NLP library that supports documents in many languages. `SpaCy` uses Machine Learning to perform NER (versus being a rule-based system)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Install the `spaCy` french pre-trained language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download fr_core_news_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the `spaCy` library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the `spaCy` french pre-trained language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_parser = spacy.load('fr_core_news_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the NER pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = spacy_parser(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the named entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Display the named entities with `displaCy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "displacy.render(doc, style=\"ent\", jupyter=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Stanza\n",
    "\n",
    "[Stanza](https://stanfordnlp.github.io/stanza/) is another NLP ML library developed by Stanford that is designed to work across many languages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Import the `Stanza` library and download the pre-trained french language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import stanza\n",
    "# This can take a while depending on your internet connection (fr model is 572M)\n",
    "stanza.download('fr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Declare the NER pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stanza_parser = stanza.Pipeline(lang='fr', processors='tokenize,ner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run the NER pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = stanza_parser(content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the named entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Geocoding\n",
    "\n",
    "\n",
    "#### 6.3.1 Quick start with the Geocoder class from the `Perdido` library\n",
    "\n",
    "The `Geocoder()` can take several parameters (all optional) such as:\n",
    "1. sources: list of gazetteers (possible values are: 'nominatim' (default), 'geonames', 'whg', 'pleiades', 'ign' (only for France))\n",
    "2. max_rows: maximum number of toponym candidates return by the gazetteer (default = 1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* The next cell shows how to create a geocoder and geocode 'Lyon':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoder = Geocoder()\n",
    "doc = geocoder('Lyon')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Show the geojson results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Map the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.get_folium_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3.1 Geocode spaCy results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Run stanza NER again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = stanza_parser(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the list of place entities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "places = [d.text for d in doc.ents if d.type == 'LOC']\n",
    "places"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Geocode the list of place entities with Periddo Geocoder:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations = geocoder(places)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Map the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locations.get_folium_map()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same method can be used for geocoding and mapping stanza NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Processing several documents at once\n",
    "\n",
    "Usually, we want to process a sample of documents, not just one. \n",
    "\n",
    "As the process can be time consuming we will first select a small sample from our dataset to show how it works.\n",
    "\n",
    "* We can use the [sample()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sample.html) method from the pandas library to select randomly a small amount of documents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sampled = dataset.sample(3)\n",
    "df_sampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Then, we keep only the text content of those documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contents = df_sampled.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`geoparser` can parse a `string`, a `list` of string or a `pandas.Series`.\n",
    "When the argument is a `list` or a `pandas.series`, the geoparser returns a `PerdidoCollection` object, while when it is a `string` it returns a `Perdido` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = geoparser(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc in docs:\n",
    "    print('-----')\n",
    "    displacy.render(doc.to_spacy_doc(), style=\"ent\", jupyter=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Explore *Encyclopédie* geoparsed example dataset\n",
    "\n",
    "Now, let's work with the same sample of articles (all of volume 7), but already processed in Perdido. Below, you can select a subsample from this dataset based on a keyword search, and then make a map of those results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Load the dataset from the library using the `load_edda_perdido()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove this cell\n",
    "from perdido.geoparser import Geoparser\n",
    "from perdido.datasets import load_edda_artfl, load_edda_perdido\n",
    "\n",
    "from spacy import displacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Load the data geocoded with Pleiades\n",
    "\n",
    "Pleiades is a gazetter of the classical world. Let's explore how it performs on this 18th-century text. The results presented here are still preliminary. The geocoding with Pleiades still needs some improvement. At the moment, querying Pleiades database only consists of a strict string match. This will be improved in futher versions of the library.\n",
    "\n",
    "We use this as an example to highlights the difficulty when dealing with historical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = load_edda_perdido('pleiades')\n",
    "dataset_pleiades = d['data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset_pleiades.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Let's do a basic keyword search:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = dataset_pleiades.keyword_search(keyword='rome')\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a brief look at these results.\n",
    "\n",
    "Which articles have places that could be located? \n",
    "What surprises you about the results?\n",
    "\n",
    "Now, let's move from the metadata to look at the text for one of the articles above: 'Funérailles des Grecs' (https://artflsrv03.uchicago.edu/philologic4/encyclopedie1117/navigate/7/1099/). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter by metadata\n",
    "collection = dataset_pleiades.filter_equal(column='head', value='Funérailles des Grecs')\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get the doc from the collection and display the NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = collection.data[0]\n",
    "displacy.render(doc.to_spacy_doc(), style=\"ent\", jupyter=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Filter by metadata for multiple articles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = dataset_pleiades.filter_in(column='head', values=['GENÈVE', 'Funérailles des Grecs'])\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get only docs that contain place names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = dataset_pleiades.filter_gt(column='#_places', value=0)\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Get only docs that contain locations (i.e. geocoded place names):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = dataset_pleiades.filter_gt(column='#_locations', value=0)\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Select the article 'Gabale' and show the NER annotations\n",
    "\n",
    "Gabale - https://artflsrv03.uchicago.edu/philologic4/encyclopedie1117/navigate/7/1219/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = dataset_pleiades.filter_equal(column='head', value='Gabale')\n",
    "collection.to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = collection.data[0]\n",
    "displacy.render(doc.to_spacy_doc(), style=\"ent\", jupyter=True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Check if locations have been found for place names using Pleiades:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.geojson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Example of geocoding 'Héliopolis' with OpenStreetMap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geocoder = Geocoder(max_rows=10)\n",
    "doc = geocoder('Héliopolis')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = doc.get_folium_map()\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Toponym disambiguation using network analysis\n",
    "\n",
    "\n",
    "As we have seen, it can be difficult to recognize a place name in a text, and even more difficult to locate that place on the earth. Researchers are actively improving methods for both of these tasks. In the last few years, the #multilingualDH community has helped to advocate for resources and methods that address the specific needs of historical, non-English languages. \n",
    "\n",
    "In our own work, we have used network analysis as a means of both aiding with toponym disambiguation and an alternative to mapping. \n",
    "\n",
    "We constructed a network based on the citation of \"géographie\" articles in any other *Encyclopédie* article (also classified as geography). As an alternative to georesolution, it diversifies the toolkit for visualizing place names in text when it's unlikely that many of those names can be geolocated. instead of mapping place names based on a geospatial location, place names in a text can be represented in a graph based on their topological, qualitative relationships. \n",
    "\n",
    ">Moncla, L., McDonough, K., Vigier, D., Joliveau, T., & Brenon, A. (2019). Toponym disambiguation in historical documents using network analysis of qualitative relationships. Proceedings of the 3rd ACM SIGSPATIAL International Workshop on Geospatial Humanities, 1–4. Chicago, IL, USA.\n",
    "\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td> <img src=\"img/labels_indegree2.png\" width =\"500px\"> </td>\n",
    "    <td> <img src=\"img/nodes_betweenness+class2.png\" width =\"500px\" > </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Node and label size indicate in-degree centrality</td>\n",
    "    <td>Node size indicates betweenness centrality<br/> \n",
    "        colors refer to geographic feature types <br/> \n",
    "        (city: red, hydronym: blue, country: green, mountain: brown, unclassified: grey)</td>\n",
    "  </tr>\n",
    "</table> \n",
    "\n",
    "\n",
    "\n",
    "We also experimented with assigning geographic coordinates found in our French wikiGazetteer to each node (headword). We have only 2535 nodes with coordinates over the 13734 nodes. \n",
    "\n",
    "Our first experiment is shown below. Colors identify clusters of nodes computed with the [modularity measure](https://en.wikipedia.org/wiki/Modularity_(networks)) implemented on Gephy.\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"img/geocodingEDDA1.png\" width =\"500\"> </td>\n",
    "<td> <img src=\"img/geocodingEDDA_network.png\" width =\"500\" > </td>\n",
    "</tr></table> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and discussion\n",
    "\n",
    "### Discussion Part 2\n",
    "\n",
    "1. How did testing Perdido on Encyclopédie text allow you to think about the texts in new ways?\n",
    "2. In what ways would geoparsing post-Classical texts shed light on Classical history/historiography?\n",
    "3. How would you describe some of the limitations of using geoparsing tools on historical texts?"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Geoparsing.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "0706207376f2dbae316cdd2388509d85cbd8c808bf8c3cd698a4e4eda55d0086"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
